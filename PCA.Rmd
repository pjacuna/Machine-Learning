---
title: "Tarea 1 - Métodos avanzados en minería de datos"
author: "Pablo Acuña Quirós"
date: "31/05/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(rmarkdown)
library(readxl)
suppressMessages(library(FactoMineR))
library(ggplot2)
library(factoextra)
library(rattle)
library(fmsb)
library(cluster)
```

###**Ejercicio 1**
####ACP e interpretación
a) Individuos y variables mal representados
```{r 1.a, echo=T, cache=FALSE, fig.align='center'}
setwd("C:/Users/paacun/Google Drive/Promidat/Metodos_Avanzados_en Mineria_de_Datos_Legrende/Tarea1")
Datos <- read.table("DatosEjercicio1.csv", header=TRUE, sep=',',dec='.',row.names=1)
pca<-PCA(Datos, scale.unit=TRUE, ncp=5, graph = FALSE)
cos2.ind<-(pca$ind$cos2[,1]+pca$ind$cos2[,2])*100
cos2.ind
plot(pca, 
     axes=c(1, 2), 
     choix="ind",
     col.ind="red",
     new.plot=TRUE,
     select="cos2 0.1")
cos2.var<-(pca$var$cos2[,1]+pca$var$cos2[,2])*100
cos2.var
plot(pca, 
     axes=c(1, 2), 
     choix="var",
     col.var="blue",
     new.plot=TRUE,
     select="cos2 0.1")
```

b) Clústeres en el plano principal
  Se logran identificar visualmente al menos cuatro clústeres:
  * Portugal, España y Noruega
  * Yugoslavia, Rumania, Bulagria y Albania
  * Grecia, Italia, HUngría y URSS
  * El resto de países

c) Correlación entre variables
  
  De acuerdo al círculo de correlación se puede concluir que el consumo de carnes (RUMI, AVES),   huevos (HUEV) y leche (LECH) tiene una alta correlación. Es decir, cuando se consume uno se     consumen también los otros. Los cereales (CERE) y las semillas (LEGU) también tienen alguna     correlación. Donde se consumen cereales (CERE) no se consumen comidas almidonadas   (ALMI) y    donde se consumen huevos (HUEV) no se consumen semillas (LEGU).

d) Formación de clústeres
```{r 1.d, echo=T, cache=FALSE, fig.align='center'}
modelo <- prcomp(Datos,scale. = TRUE,center = TRUE)
modelo
biplot(modelo)
```
Se puede observar que países como Portugal, España y Noruega eran consumidores de frutas, verduras y carne de pescado como principal fuente de proteína. Alemania, Dinamarca, Polonia, Francia eran consumidores principalmente de comidas almidonadas. Finlandia, Suiza, Holanda, Austria, etc consumían carnes, huevos y leche; en otras palabras países ganaderos principalmente. Grecia e Italia consumían semillas. Yogoslavia, Albania, Bulgaria, etc grandes consumidores de cereales.



####Funciones Fviz del paquete Factoextra
```{r Fviz, echo=T, cache=FALSE, fig.align='center'}
# Gráfico de individuos
fviz_pca_ind(pca,axes = c(1, 2), geom = c("point", "text"),
       label = "all", invisible = "none", labelsize = 4,
       pointsize = 2, habillage = "none",
       addEllipses = FALSE, ellipse.level = 1, 
       col.ind = "red", col.ind.sup = "blue", alpha.ind = 1,
       select.ind = list(name = NULL, cos2 = 0.1, contrib = NULL))
# Gráfico de variables
fviz_pca_var(pca, axes = c(1, 2), geom = c("arrow", "text"),
       label = "all", invisible = "none", labelsize = 4,
       col.var = "blue", alpha.var = 1, col.quanti.sup = "blue",
       col.circle = "grey70",
       select.var = list(name =NULL, cos2 = 0.1, contrib = NULL))
# Biplot de variables e individuos
fviz_pca_biplot(pca, axes = c(1, 2), geom = c("point", "text"),
   label = "all", invisible = "none", labelsize = 4, pointsize = 2,
    habillage = "none", addEllipses = FALSE, ellipse.level = 1,
    col.ind = "red", col.ind.sup = "blue", alpha.ind = 1,
    col.var = "blue", alpha.var = 1, col.quanti.sup = "blue",
    col.circle = "grey70", 
    select.var = list(name = NULL, cos2 = 0.1, contrib= NULL), 
    select.ind = list(name = NULL, cos2 = 0.1, contrib = NULL))
```



####Plano Principal y mapa de Europa
Se puede observar que si el plano principal se rota 90 grados en contra de las manecillas del reloj, se asemeja a la ubicación geográfica de los países en el mapa mundial. Esto también concuerda en cómo se agrupan los países según el consumo de proteínas.



###**Ejercicio 2**
```{r 2.1, echo=T, cache=FALSE, fig.align='center'}
#a) ACP con prcomp
setwd("C:/Users/paacun/Google Drive/Promidat/Metodos_Avanzados_en Mineria_de_Datos_Legrende/Tarea1")
Datos.2 <- read.table("EjemploAlgoritmosRecomendacion.csv", header=TRUE, sep=';',dec=',',row.names=1)
modelo <- prcomp(Datos.2,scale. = TRUE,center = TRUE)
modelo
biplot(modelo)
#b) Biplot con fviz
fviz_pca_biplot(modelo, axes = c(1, 2), geom = c("point", "text"),
   label = "all", invisible = "none", labelsize = 4, pointsize = 2,
    habillage = "none", addEllipses = FALSE, ellipse.level = 1,
    col.ind = "black", col.ind.sup = "blue", alpha.ind = 1,
    col.var = "red", alpha.var = 1, col.quanti.sup = "blue",
    col.circle = "grey70", 
    select.var = list(name = NULL, cos2 = 0.1, contrib= NULL), 
    select.ind = list(name = NULL, cos2 = 0.1, contrib = NULL))
#c) ACP con FactoMineR
pca.2<-PCA(Datos.2, scale.unit=TRUE, ncp=5, graph = FALSE)
cos2.ind<-(pca.2$ind$cos2[,1]+pca.2$ind$cos2[,2])*100
cos2.ind
plot(pca.2, 
     axes=c(1, 2), 
     choix="ind",
     col.ind="red",
     new.plot=TRUE,
     select="cos2 0.2")
cos2.var<-(pca.2$var$cos2[,1]+pca.2$var$cos2[,2])*100
cos2.var
plot(pca.2, 
     axes=c(1, 2), 
     choix="var",
     col.var="blue",
     new.plot=TRUE,
     select="cos2 0.55")
#d) fviz_pca_ind y fviz_pca_var
fviz_pca_ind(pca.2,axes = c(1, 2), geom = c("point", "text"),
       label = "all", invisible = "none", labelsize = 4,
       pointsize = 2, habillage = "none",
       addEllipses = FALSE, ellipse.level = 1, 
       col.ind = "red", col.ind.sup = "blue", alpha.ind = 1,
       select.ind = list(name = NULL, cos2 = 0.1, contrib = NULL))
fviz_pca_var(pca.2, axes = c(1, 2), geom = c("arrow", "text"),
       label = "all", invisible = "none", labelsize = 4,
       col.var = "blue", alpha.var = 1, col.quanti.sup = "blue",
       col.circle = "grey70",
       select.var = list(name =NULL, cos2 = 0.1, contrib = NULL))
#e) Clustering Jerárquico
modelo1 <- hclust(dist(Datos.2),method = "complete")
plot(modelo1,hang=-1)
rect.hclust(modelo1, k=3, border="red")
modelo2 <- hclust(dist(Datos.2),method = "single")
plot(modelo2,hang=-1)
rect.hclust(modelo2, k=3, border="blue")
modelo3 <- hclust(dist(Datos.2),method = "average")
plot(modelo3,hang=-1)
rect.hclust(modelo3, k=3, border="green")
modelo4 <- hclust(dist(Datos.2),method = "ward")
plot(modelo4,hang=-1)
rect.hclust(modelo4, k=3, border="magenta")
Grupo<-cutree(modelo4,k=3)
NDatos.2<-cbind(Datos.2,Grupo)
write.csv(NDatos.2,"AlgoritmosRecomendacion2.csv")
#f) Interpretación de resultados
centros<-centers.hclust(Datos.2,modelo4,nclust=3,use.median=FALSE)
centros
rownames(centros)<-c("Cluster 1","Cluster 2","Cluster 3")
barplot(centros[1,],col=c(2,3,4,5,6,7,8,9),las=2)
barplot(centros[2,],col=c(2,3,4,5,6,7,8,9),las=2)
barplot(centros[3,],col=c(2,3,4,5,6,7,8,9),las=2)
barplot(t(centros),beside=TRUE,col=c(2,3,4,5,6,7,8,9))
centros<-as.data.frame(centros)
maximos<-apply(centros,2,max)
minimos<-apply(centros,2,min)
centros<-rbind(minimos,centros)
centros<-rbind(maximos,centros)
centros
radarchart(centros,maxmin=TRUE,axistype=4,axislabcol="slategray4",
           centerzero=FALSE,seg=8,cglcol="gray67",
           pcol=c("green","blue","red"),
           plty=1,
           plwd=5,
           title="Comparación de clústeres")

legenda <-legend(1.5,1, legend=c("Cluster 1","Cluster 2","Cluster 3"),
                 seg.len=-1.4,
                 title="Clústeres",
                 pch=21, 
                 bty="n" ,lwd=3, y.intersp=1, horiz=FALSE,
                 col=c("green","blue","red"))
```
Los individuos del clúster 1 son los que peor califican los productos mientras que los del clúster 2 son los que en general mejor califican. Los individuos del clúster 3 califican algunos aspectos muy bien y otros muy mal.
```{r 2.2, echo=T, cache=FALSE, fig.align='center'}
#g) Clustering jerárquico sobre componentes principales
res.hcpc<-HCPC(pca.2 ,nb.clust=-1,consol=TRUE,min=3,max=3,graph=FALSE)
#plot.HCPC(res.hcpc, choice="bar")
#plot.HCPC(res.hcpc, choice="map")
#plot.HCPC(res.hcpc, choice="3D.map", angle=60)
#h) Método de K-medias
grupos<-kmeans(Datos.2,4,iter.max=200)
# Inercia Total
grupos$totss 
# Inercia Intra-clases
grupos$tot.withinss
# inercia Inter-clases
grupos$betweenss
# Verificación del Teorema de Fisher
grupos$totss==grupos$tot.withinss+grupos$betweenss
#i) Interpretación de resultados
barplot(grupos$centers[1,],col='blue',las=2)
barplot(grupos$centers[2,],col='red',las=2)
barplot(grupos$centers[3,],col='green',las=2)
barplot(grupos$centers[4,],col='orange',las=2)
rownames(grupos$centers)<-c("Cluster 1","Cluster 2","Cluster 3","Cluster 4")
barplot(t(grupos$centers),beside=TRUE,main = "Gráfico de Interpretación de Clases",col=c(1,2,3,4,5,6,7,8,9),ylim=c(0,10))
centros<-grupos$centers
rownames(centros)<-c("Cluster 1","Cluster 2","Cluster 3","Cluster 4")
centros<-as.data.frame(centros)
maximos<-apply(centros,2,max)
minimos<-apply(centros,2,min)
centros<-rbind(minimos,centros)
centros<-rbind(maximos,centros)
centros
radarchart(centros,maxmin=TRUE,axistype=4,axislabcol="slategray4",
           centerzero=FALSE,seg=8,cglcol="gray67",
           pcol=c("green","blue","red","orange"),
           plty=1,
           plwd=5,
           title="Comparación de clústeres")

legenda <-legend(1.5,1, legend=c("Cluster 1","Cluster 2","Cluster 3","Cluster 4"),
                 seg.len=-1.4,
                 title="Clústeres",
                 pch=21, 
                 bty="n" ,lwd=3, y.intersp=1, horiz=FALSE,
                 col=c("green","blue","red","orange"))
```
Los individuos del clúster 3 son los que mejor califican mientras que los del clúster 2 los que peor lo hacen. Los del clúster 1 se encuentran entre los que califican bien algunas características y otras no tan bien.
```{r 2.3, echo=T, cache=FALSE, fig.align='center'}
#j) Codo de Jambu
InerciaIC<-rep(0,50)
for(k in 1:50) {
   grupos<-kmeans(Datos.2,k,iter.max = 200)
   InerciaIC[k]<-grupos$tot.withinss
}
plot(InerciaIC,col="blue",type="b")
```
La inercia se estabiliza cerca de k = 11


###**Ejercicio 3**

a) Abstract:

Relative CPU Performance Data, described in terms of its cycle time, memory size, etc.


Attribute Information:

* Vendor: 30 (adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec, dg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson, microdata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry, sratus, wang)

* Model Name: many unique symbols

* MYCT: machine cycle time in nanoseconds (integer) 

* MMIN: minimum main memory in kilobytes (integer) 

* MMAX: maximum main memory in kilobytes (integer) 

* CACH: cache memory in kilobytes (integer) 

* CHMIN: minimum channels in units (integer) 

* CHMAX: maximum channels in units (integer) 

* PRP: published relative performance (integer)

* ERP: estimated relative performance from the original article (integer)

```{r 3.1, echo=T, cache=FALSE, fig.align='center'}
#b) Clústering jerárquico
Datos.3 <- read.csv("machine.csv",header=TRUE, sep=",", dec=".")
str(Datos.3)
dim(Datos.3)
D<-daisy(Datos.3, metric = "euclidean")
jer<-hclust(D, method = "complete")
plot(jer)
rect.hclust(jer, k = 4, border = "red")
#Interpretación con datos cuantitativos
centros<-centers.hclust(Datos.3[,-c(1,2)],jer,nclust=4,use.median=FALSE)
centros
rownames(centros)<-c("Cluster 1","Cluster 2","Cluster 3","Cluster 4")
centros<-as.data.frame(centros)
maximos<-apply(centros,2,max)
minimos<-apply(centros,2,min)
centros<-rbind(minimos,centros)
centros<-rbind(maximos,centros)
centros
radarchart(centros,maxmin=TRUE,axistype=4,axislabcol="slategray4",
           centerzero=FALSE,seg=8,cglcol="gray67",
           pcol=c("green","blue","red","orange"),
           plty=1,
           plwd=5,
           title="Comparación de clústeres")

legenda <-legend(1.5,1, legend=c("Cluster 1","Cluster 2","Cluster 3","Cluster 4"),
                 seg.len=-1.4,
                 title="Clústeres",
                 pch=21, 
                 bty="n" ,lwd=3, y.intersp=1, horiz=FALSE,
                 col=c("green","blue","red","orange"))
```
Según el gráfico de araña hay un grupo de CPU's (clúster 1) con buena memoria caché pero quedan rezagados en las demás características. Los elementos de clúster 2 tiene la duración de ciclos más grande, asimismo un desempeño malo en las otras caracterísicas. Los CPU's del clúster 3 son regulares en todo y finalmente los del clúster4 son los sobresalientes, cuya duración de ciclo esla más baja y tiene los valores más altos en casi todas las características.

```{r 3.2, echo=T, cache=FALSE, fig.align='center'}
#Interpretación con variables cualitativas
grupo <- cutree(jer, k = 4)
NDatos <- cbind(Datos.3, grupo)
cluster <- NDatos$grupo
sel.cluster1 <- match(cluster, 1, 0)
Datos.Cluster1 <- NDatos[sel.cluster1 > 0,]
dim(Datos.Cluster1)
sel.cluster2 <- match(cluster, 2, 0)
Datos.Cluster2 <- NDatos[sel.cluster2 > 0,]
dim(Datos.Cluster2)
sel.cluster3 <- match(cluster, 3, 0)
Datos.Cluster3 <- NDatos[sel.cluster3 > 0,]
dim(Datos.Cluster3)
sel.cluster4 <- match(cluster, 4, 0)
Datos.Cluster4 <- NDatos[sel.cluster4 > 0,]
dim(Datos.Cluster4)
plot(Datos.3$Vendor, col = heat.colors(30), las = 2, main = "Variable Vendor - Todos los datos")
plot(Datos.Cluster1$Vendor, col = heat.colors(30), las = 2, main = "Variable Vendor - Clúster 1")
plot(Datos.Cluster2$Vendor, col = heat.colors(30), las = 2, main = "Variable Vendor - Clúster 2")
plot(Datos.Cluster3$Vendor, col = heat.colors(30), las = 2, main = "Variable Vendor - Clúster 3")
plot(Datos.Cluster4$Vendor, col = heat.colors(30), las = 2, main = "Variable Vendor - Clúster 4")
```
Se observa como la mayoría de CPU's caen en el clúster 2, apenas 3 CPU's son los que tienen un desempeño sobresaliente (clúster 4).

```{r 3.3, echo=T, cache=FALSE, fig.align='center'}
res <- cmdscale(D,eig=TRUE, k=2) 
x <- res$points[,1]
y <- res$points[,2]
plot(x, y, xlab="Componente 1", ylab="Componente 2",main="MDS", type="n")
text(x, y, labels = row.names(Datos.3), cex=.7) 
```
De acuerdo a este Escalamiento Multidimensional se pueden identificar 2 o hasta 3 clústeres bien definidos.


###**Ejercicio 4**



```{r 4.1, echo=T, cache=FALSE, fig.align='center'}
#1) Identificar individuos y variables mal representados
Datos.4 <- read.table("DatosEjercicio4.csv", header=TRUE, sep=',',dec='.',row.names=1)
pca.4<-PCA(Datos.4, scale.unit=TRUE, ncp=5, graph = FALSE)
cos2.ind<-(pca.4$ind$cos2[,1]+pca.4$ind$cos2[,2])*100
cos2.ind
cos2.var<-(pca.4$var$cos2[,1]+pca.4$var$cos2[,2])*100
cos2.var
#2) Clústeres en el Plano Principal
fviz_pca_ind(pca.4,axes = c(1, 2), geom = c("point", "text"),
       label = "all", invisible = "none", labelsize = 4,
       pointsize = 2, habillage = "none",
       addEllipses = FALSE, ellipse.level = 1, 
       col.ind = "red", col.ind.sup = "blue", alpha.ind = 1,
       select.ind = list(name = NULL, cos2 = 0.1, contrib = NULL))
```
En el plano principal se logran identificar visualmente 3 o 4 clústeres.

```{r 4.2, echo=T, cache=FALSE, fig.align='center'}
#3) Círculo de correlaciones
fviz_pca_var(pca.4, axes = c(1, 2), geom = c("arrow", "text"),
       label = "all", invisible = "none", labelsize = 4,
       col.var = "blue", alpha.var = 1, col.quanti.sup = "blue",
       col.circle = "grey70",
       select.var = list(name =NULL, cos2 = 0.1, contrib = NULL))
```

*	Se observa una alta correlación entre Caterpillar con empresas como Du Pont, IBM y McDonalds.

*	McDonalds y DuPont presentan una alta correlación entre sí con respecto al índice DJI.

*	Coca Cola e IBM también presentan una alta correlación entre sí.

*	El índice de AT&T presenta una alta correlación con el de Coca Cola.

*	Dos empresas de Telecomunicaciones como los son Verizon Wireless y AT&T tienen una alta correlación en sus índices.

```{r 4.3, echo=T, cache=FALSE, fig.align='center'}
#4) Sobreposición del círculo y el plano
fviz_pca_biplot(pca.4, axes = c(1, 2), geom = c("point", "text"),
   label = "all", invisible = "none", labelsize = 4, pointsize = 2,
    habillage = "none", addEllipses = FALSE, ellipse.level = 1,
    col.ind = "red", col.ind.sup = "blue", alpha.ind = 1,
    col.var = "blue", alpha.var = 1, col.quanti.sup = "blue",
    col.circle = "grey70", 
    select.var = list(name = NULL, cos2 = 0.1, contrib= NULL), 
    select.ind = list(name = NULL, cos2 = 0.1, contrib = NULL))
```

*	Se observa en términos generales que el clúster de los cuadrantes superiores contiene individuos cuyos índices se comportan similares para las compañías BAC, CSCO, MSFT, GE, WMT, XOM, entre otros.

*	En las fechas del cuadrante inferior derecho, la variación de los índices tuvo un comportamiento parecido para compañías como McDonald's, Caterpillar, IBM, AT&T, Verizon entre otras.

```{r 4.4, echo=T, cache=FALSE, fig.align='center'}
#5) Interpretación del plano principal
``` 
Analizando el plano principal, mi interpretación es que a durante el año 2010 la variación de los índices siguió un comportamiento de "temporadas", es decir, dependiendo de la fecha el comportamiento (variación) del índice DJ es similar para algunas empresas y conforme pasa el tiempo deja de serlo para estas empresas, comenzando a serlo para otras. Durante un tiempo durante el año, representado en el plano principal en el cuadrante inferior izquierdo, ninguno de los mercados se comportan de manera similar entre sí.


###**Ejercicio 5**
```{r 5.1, echo=T, cache=FALSE, fig.align='center'}
eurodist.matriz <- as.matrix(eurodist)
eurodist.matriz
res5 <- cmdscale(eurodist,eig=TRUE, k=2)
x <- res5$points[,1]
y <- res5$points[,2]
plot(x, y, xlab="Componente 1", ylab="Componente 2",main="MDS", type="n")
text(x, y, labels = row.names(eurodist.matriz), cex=.7)
#Rotación
y <- -y
plot(x, y, xlab="Componente 1", ylab="Componente 2",main="MDS con rotación", type="n")
text(x, y, labels = row.names(eurodist.matriz), cex=.7)
``` 

Rotando el MDS por el eje y se obtiene una ubicación en el plot que se asemeja a la ubicación en el mapa.



###**Optativa**
```{r 6.1, echo=T, cache=TRUE, fig.align='center'}

#a) Función distancia de Chebychev
chebyshev <- function(u,v) {
  dmax <- NA
  dmax <- max (abs(u-v))
  return(dmax)
}

#b) Función matriz de distancias
matriz <- function(df) {
  df2 <- df
  for (i in 1:nrow(df)) {
    for (j in 1:nrow(df)) {
      df2[j,i] <- chebyshev(as.vector(df[i,]),as.vector(df[j,]))
    }
  }
  df3 <- as.dist(df2)
  return(df3)
}

#c) Clústering jerárquico con distancia de Chebysev
Datos.6 <- read.table("EjemploAlgoritmosRecomendacion.csv", header=TRUE, sep=';',dec=',',row.names=1)
modelo6 <- hclust(matriz(Datos.6),method = "ward")
plot(modelo6,hang=-1)
rect.hclust(modelo6, k=3, border="magenta")
centros<-centers.hclust(Datos.6,modelo6,nclust=3,use.median=FALSE)
rownames(centros)<-c("Cluster 1","Cluster 2","Cluster 3")
centros<-as.data.frame(centros)
maximos<-apply(centros,2,max)
minimos<-apply(centros,2,min)
centros<-rbind(minimos,centros)
centros<-rbind(maximos,centros)
radarchart(centros,maxmin=TRUE,axistype=4,axislabcol="slategray4",
           centerzero=FALSE,seg=8,cglcol="gray67",
           pcol=c("green","blue","red"),
           plty=1,
           plwd=5,
           title="Comparación de clústeres")

legenda <-legend(1.5,1, legend=c("Cluster 1","Cluster 2","Cluster 3"),
                 seg.len=-1.4,
                 title="Clústeres",
                 pch=21, 
                 bty="n" ,lwd=3, y.intersp=1, horiz=FALSE,
                 col=c("green","blue","red"))
```
Presenta variaciones principalmente en el clúster 1, otorgando mejor calificación a Servicio de Retorno e Imagen de Producto.
